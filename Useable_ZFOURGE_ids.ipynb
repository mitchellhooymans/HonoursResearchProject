{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Useable ZFOURGE Id's \n",
    "This will be used to get the useable ZFOURGE Id's that will be used in the output code\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Import all relevant libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import astropy.units as u\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from astLib import astSED\n",
    "import astropy.io.fits as fits\n",
    "from carf import * # custom module for functions relating to the project\n",
    "import matplotlib.path as mpath\n",
    "\n",
    "\n",
    "# So that we can change the helper functions without reloading the kernel\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We would like to read in the fits files that we are exploring in this project\n",
    "# This is related to the data that we are using\n",
    "# we will be looking at all fields so it will be easier to read in all required fits files, and all recalculated IDs and combine these \n",
    "# into three master dataframes.\n",
    "# From here we will be able to check the best values for each and eventually select some reliabile samples\n",
    "\n",
    "zfourge_path = 'datasets/zfourge/'\n",
    "\n",
    "# Read in ZFourge Data in each field\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_zfourge_data(fieldname, folderpath): # Define a function to read in zfourge data, this will be added to the helper package later\n",
    "    # Dictionary to read from\n",
    "    zfourge_fields = {\n",
    "    'CDFS': ['zf_cdfs.fits', 'zf_cdfs_rest.fits', 'zf_cdfs_eazy.fits', 'zf_cdfs_sfr.fits'],\n",
    "    'COSMOS': ['zf_cosmos.fits', 'zf_cosmos_rest.fits', 'zf_cosmos_eazy.fits', 'zf_cosmos_sfr.fits'],\n",
    "    'UDS': ['zf_uds.fits', 'zf_uds_rest.fits', 'zf_uds_eazy.fits', 'zf_uds_sfr.fits'],\n",
    "}\n",
    "    \n",
    "    folder = folderpath\n",
    "    \n",
    "    # Construct file paths using os.path.join() to make it platform-independent\n",
    "    catalog_file = os.path.join(folder, zfourge_fields[fieldname][0])\n",
    "    rest_file = os.path.join(folder, zfourge_fields[fieldname][1])\n",
    "    eazy_file = os.path.join(folder, zfourge_fields[fieldname][2])\n",
    "    sfr_file = os.path.join(folder, zfourge_fields[fieldname][3])\n",
    "    \n",
    "    # Open the fits files <- needs to be different for CAT vs Fits files\n",
    "    catalog_fits = fits.open(catalog_file)\n",
    "    rest_fits = fits.open(rest_file)\n",
    "    sfr_fits = fits.open(sfr_file)\n",
    "    \n",
    "    # Read the files into DataFrames <- needs to be different for CAT vs Fits files\n",
    "    df = pd.DataFrame(np.array(catalog_fits[1].data).byteswap().newbyteorder()) \n",
    "    rest_df = pd.DataFrame(np.array(rest_fits[1].data).byteswap().newbyteorder())\n",
    "    eazy_df = pd.DataFrame(np.array(fits.open(eazy_file)[1].data).byteswap().newbyteorder())\n",
    "    sfr_df = pd.DataFrame(np.array(sfr_fits[1].data).byteswap().newbyteorder())\n",
    "    \n",
    "    \n",
    "    # Rename the Seq column to id for consistency\n",
    "    df.rename(columns={'Seq':'id'}, inplace=True)\n",
    "    rest_df.rename(columns={'Seq':'id', 'FU':'U', 'e_FU':'eU', 'FV':'V', 'e_FV':'eV', 'FJ':'J','e_FJ':'eJ'}, inplace=True)\n",
    "    eazy_df.rename(columns={'Seq':'id'}, inplace=True)\n",
    "    sfr_df.rename(columns={'Seq':'id'}, inplace=True)\n",
    "    \n",
    "    \n",
    "    # We now merge the two dataframes into one dataframe, adding a suffix _rest if columns clash\n",
    "    #df = pd.merge(df, rest_df, on='id', suffixes=('', '_rest'))\n",
    "    \n",
    "    # we now merge rest and df into one\n",
    "    #df = pd.concat([df, rest_df], axis=1)\n",
    "    df = pd.merge(df, rest_df[['id', 'U', 'eU', 'V', 'eV', 'J','eJ']], on='id', suffixes=('_original', '_rest'))\n",
    "    df = pd.merge(df, eazy_df[['id', 'zpk']], on='id', suffixes=('', '_eazy'))\n",
    "    df = pd.merge(df, sfr_df[['id', 'lssfr', 'lmass']], on='id', suffixes=('', '_sfr'))\n",
    "    \n",
    "    \n",
    "    # Create a new column to mark the field that this data is from\n",
    "    df['field'] = fieldname + \"_\"\n",
    "    \n",
    "    # In this scenario we don't need to append which field it's from\n",
    "    fieldname = \"\"\n",
    "    \n",
    "    # rename the number in the id column to be prefixed by the fieldname, this is to avoid confusion when merging dataframes\n",
    "    df['id'] = fieldname + df['id'].astype(str)\n",
    "    \n",
    "    # return the created dataframe\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#CDFS, COSMOS, UDS\n",
    "cdfs_df = read_zfourge_data('CDFS', zfourge_path)\n",
    "cosmos_df = read_zfourge_data('COSMOS', zfourge_path)\n",
    "uds_df = read_zfourge_data('UDS', zfourge_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cdfs has 12277 useable sources\n",
      "cosmos has 11741 useable sources\n",
      "uds has 10556 useable sources\n"
     ]
    }
   ],
   "source": [
    "df_names = ['cdfs', 'cosmos', 'uds']\n",
    "i = 0\n",
    "# create a dictionary\n",
    "id_dict = {'id': [], 'z': [], 'field': []}\n",
    "for df in [cdfs_df, cosmos_df, uds_df]:\n",
    "    # Filter the data as necessay\n",
    "    # flux filtering, set a sigma value for the flux error ratio\n",
    "    sigma = 3\n",
    "\n",
    "# optionally we can filter the data into fields\n",
    "#field = 'CDFS'\n",
    "#df = df[df['field'] == field].copy()\n",
    "\n",
    "    # filter for uvj colours, making sure that there isn't a flux below 0\n",
    "    df = df[(df['U'] > 0) & (df['V'] > 0) & (df['J'] > 0) & (df['eU'] > 0) & (df['eV'] > 0) & (df['eJ'] > 0) & (df['Use']==1)].copy()\n",
    "\n",
    "    # we also need to filter by the redshift, Z-fourge only has reliable accuracy for redshifts between 0.2 and 3.2 ~ potentially up to a redshift of 4\n",
    "    # As my project will be investigating redshifts of galaxies where z-0.5~2 we should instead use this range\n",
    "    min_redshift = 0\n",
    "    max_redshift = 5\n",
    "\n",
    "    df = df[(df['zpk'] > min_redshift) & (df['zpk'] < max_redshift)].copy()\n",
    "\n",
    "\n",
    "\n",
    "    # Propogate errors from each of the fluxes to the UVJ diagram to a ratio of sigma\n",
    "    df = df[(df['U'] >= sigma * df['eU']) & (df['V'] >= sigma * df['eV']) & (df['J'] >= sigma * df['eJ'])].copy()\n",
    "    \n",
    "    \n",
    "    # append the id, z and field to the dictionary\n",
    "    id_dict['id'].extend(df['id'])\n",
    "    id_dict['z'].extend(df['zpk'])\n",
    "    id_dict['field'].extend([df_names[i]]*len(df))\n",
    "    \n",
    "    \n",
    "    \n",
    "        \n",
    "    print(f'{df_names[i]} has {len(df)} useable sources')\n",
    "    i+=1\n",
    "\n",
    "\n",
    "# Checkout the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34574 34574 34574\n"
     ]
    }
   ],
   "source": [
    "id_dict\n",
    "\n",
    "# Check length of each array in the dict\n",
    "print(len(id_dict['id']), len(id_dict['z']), len(id_dict['field']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Have a look at the uds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_df = pd.DataFrame(id_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output the ids to a csv file\n",
    "id_df.to_csv('outputs/useable_zfourge_ids.csv', index=False)\n",
    "# Output the ids to a csv file\n",
    "id_df.to_csv('Eazy Template Extractions/useable_zfourge_ids.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the max redshift for the uds\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eazy39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
